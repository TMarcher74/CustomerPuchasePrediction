{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216a313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the data\n",
    "data_path = 'activity_data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(data):\n",
    "    # Convert categorical columns to numeric\n",
    "    label_encoders = {}\n",
    "    for column in ['Month', 'VisitorType']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "    \n",
    "    # Convert boolean columns to numeric\n",
    "    data['Weekend'] = data['Weekend'].astype(int)\n",
    "    data['Revenue'] = data['Revenue'].astype(int)\n",
    "    \n",
    "    # Split data into features and target\n",
    "    X = data.drop('Revenue', axis=1)\n",
    "    y = data['Revenue']\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cb18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=3000)  # Increased max_iter\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "logistic_predictions = logistic_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff848282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train Decision Tree model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "tree_predictions = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d9da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest model\n",
    "forest_model = RandomForestClassifier(random_state=42)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "forest_predictions = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6a4cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Logistic Regression:\n",
      "Accuracy: 0.8690186536901865\n",
      "Confusion Matrix:\n",
      " [[2002   53]\n",
      " [ 270  141]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93      2055\n",
      "           1       0.73      0.34      0.47       411\n",
      "\n",
      "    accuracy                           0.87      2466\n",
      "   macro avg       0.80      0.66      0.70      2466\n",
      "weighted avg       0.86      0.87      0.85      2466\n",
      "\n",
      "\n",
      "\n",
      "Evaluation of Decision Tree:\n",
      "Accuracy: 0.8572587185725872\n",
      "Confusion Matrix:\n",
      " [[1879  176]\n",
      " [ 176  235]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      2055\n",
      "           1       0.57      0.57      0.57       411\n",
      "\n",
      "    accuracy                           0.86      2466\n",
      "   macro avg       0.74      0.74      0.74      2466\n",
      "weighted avg       0.86      0.86      0.86      2466\n",
      "\n",
      "\n",
      "\n",
      "Evaluation of Random Forest:\n",
      "Accuracy: 0.8957826439578265\n",
      "Confusion Matrix:\n",
      " [[1985   70]\n",
      " [ 187  224]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      2055\n",
      "           1       0.76      0.55      0.64       411\n",
      "\n",
      "    accuracy                           0.90      2466\n",
      "   macro avg       0.84      0.76      0.79      2466\n",
      "weighted avg       0.89      0.90      0.89      2466\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define an evaluation function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"Evaluation of {model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "evaluate_model(y_test, logistic_predictions, \"Logistic Regression\")\n",
    "\n",
    "# Evaluate Decision Tree model\n",
    "evaluate_model(y_test, tree_predictions, \"Decision Tree\")\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "evaluate_model(y_test, forest_predictions, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d262ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193cd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# # Feature importance for Random Forest\n",
    "# importances = best_forest.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# features = X.columns\n",
    "\n",
    "# # Plot feature importances\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.title(\"Feature Importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), features[indices], rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04b94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# # Load the data\n",
    "# data_path = 'activity_data.csv'\n",
    "# data = pd.read_csv(data_path)\n",
    "\n",
    "# # Preprocess the data\n",
    "# def preprocess_data(data):\n",
    "#     # Convert categorical columns to numeric\n",
    "#     label_encoders = {}\n",
    "#     for column in ['Month', 'VisitorType']:\n",
    "#         label_encoders[column] = LabelEncoder()\n",
    "#         data[column] = label_encoders[column].fit_transform(data[column])\n",
    "    \n",
    "#     # Convert boolean columns to numeric\n",
    "#     data['Weekend'] = data['Weekend'].astype(int)\n",
    "#     data['Revenue'] = data['Revenue'].astype(int)\n",
    "    \n",
    "#     # Split data into features and target\n",
    "#     X = data.drop('Revenue', axis=1)\n",
    "#     y = data['Revenue']\n",
    "    \n",
    "#     # Scale the features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "#     return X, X_scaled, y\n",
    "\n",
    "# X, X_scaled, y = preprocess_data(data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4dd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid_tree = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 10, 20]}\n",
    "\n",
    "# # Decision Tree model\n",
    "# tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # Hyperparameter tuning using GridSearchCV\n",
    "# grid_tree = GridSearchCV(tree, param_grid_tree, cv=5, scoring='accuracy')\n",
    "# grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# # Best Decision Tree model\n",
    "# best_tree = grid_tree.best_estimator_\n",
    "\n",
    "# # Make predictions\n",
    "# tree_predictions = best_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6b1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid_forest = {'n_estimators': [100, 200, 300], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# # Random Forest model\n",
    "# forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Hyperparameter tuning using GridSearchCV\n",
    "# grid_forest = GridSearchCV(forest, param_grid_forest, cv=5, scoring='accuracy')\n",
    "# grid_forest.fit(X_train, y_train)\n",
    "\n",
    "# # Best Random Forest model\n",
    "# best_forest = grid_forest.best_estimator_\n",
    "\n",
    "# # Make predictions\n",
    "# forest_predictions = best_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362c8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# # Define an evaluation function\n",
    "# def evaluate_model(y_true, y_pred, model_name):\n",
    "#     print(f\"Evaluation of {model_name}:\")\n",
    "#     print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "#     print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "#     print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# # Evaluate Logistic Regression model\n",
    "# evaluate_model(y_test, logistic_predictions, \"Tuned Logistic Regression\")\n",
    "\n",
    "# # Evaluate Decision Tree model\n",
    "# evaluate_model(y_test, tree_predictions, \"Tuned Decision Tree\")\n",
    "\n",
    "# # Evaluate Random Forest model\n",
    "# # evaluate_model(y_test, forest_predictions, \"Tuned Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f678e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
