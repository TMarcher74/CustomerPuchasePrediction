{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9859a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 2145\n",
      "Incorrect: 321\n",
      "True Positive Rate: 36.50%\n",
      "True Negative Rate: 97.08%\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93      2055\n",
      "           1       0.71      0.36      0.48       411\n",
      "\n",
      "    accuracy                           0.87      2466\n",
      "   macro avg       0.80      0.67      0.70      2466\n",
      "weighted avg       0.86      0.87      0.85      2466\n",
      "\n",
      "Accuracy:  86.98296836982968\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def load_data(filename):\n",
    "    evidence = []\n",
    "    labels = []\n",
    "\n",
    "    month_index = {\n",
    "        \"Jan\": 0, \"Feb\": 1, \"Mar\": 2, \"Apr\": 3, \"May\": 4, \"June\": 5,\n",
    "        \"Jul\": 6, \"Aug\": 7, \"Sep\": 8, \"Oct\": 9, \"Nov\": 10, \"Dec\": 11\n",
    "    }\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            evidence.append([\n",
    "                int(row[\"Administrative\"]),\n",
    "                float(row[\"Administrative_Duration\"]),\n",
    "                int(row[\"Informational\"]),\n",
    "                float(row[\"Informational_Duration\"]),\n",
    "                int(row[\"ProductRelated\"]),\n",
    "                float(row[\"ProductRelated_Duration\"]),\n",
    "                float(row[\"BounceRates\"]),\n",
    "                float(row[\"ExitRates\"]),\n",
    "                float(row[\"PageValues\"]),\n",
    "                float(row[\"SpecialDay\"]),\n",
    "                month_index[row[\"Month\"]],\n",
    "                int(row[\"OperatingSystems\"]),\n",
    "                int(row[\"Browser\"]),\n",
    "                int(row[\"Region\"]),\n",
    "                int(row[\"TrafficType\"]),\n",
    "                1 if row[\"VisitorType\"] == \"Returning_Visitor\" else 0,\n",
    "                1 if row[\"Weekend\"] == \"TRUE\" else 0,\n",
    "            ])\n",
    "            labels.append(1 if row[\"Revenue\"] == \"TRUE\" else 0)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    t_positive = float(0)\n",
    "    t_negative = float(0)\n",
    "    sensitivity = float(0)\n",
    "    specificity = float(0)\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == 0:\n",
    "            t_negative += 1\n",
    "            if label == prediction:\n",
    "                specificity += 1\n",
    "\n",
    "        if label == 1:\n",
    "            t_positive += 1\n",
    "            if label == prediction:\n",
    "                sensitivity += 1\n",
    "\n",
    "    sensitivity /= t_positive\n",
    "    specificity /= t_negative\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Replace 'Data/activity_data.csv' with the path to your CSV file\n",
    "filename = 'activity_data.csv'\n",
    "\n",
    "evidence, labels = load_data(filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVC\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "sensitivity, specificity = evaluate(y_test, predictions)\n",
    "print(f\"Correct: {(y_test == predictions).sum()}\")\n",
    "print(f\"Incorrect: {(y_test != predictions).sum()}\")\n",
    "print(f\"True Positive Rate: {100 * sensitivity:.2f}%\")\n",
    "print(f\"True Negative Rate: {100 * specificity:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d5b13",
   "metadata": {},
   "source": [
    "# SVM with RBF Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647006c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF Kernel\n",
      "Correct: 2167\n",
      "Incorrect: 299\n",
      "True Positive Rate: 42.09%\n",
      "True Negative Rate: 97.03%\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      2055\n",
      "           1       0.74      0.42      0.54       411\n",
      "\n",
      "    accuracy                           0.88      2466\n",
      "   macro avg       0.82      0.70      0.73      2466\n",
      "weighted avg       0.87      0.88      0.86      2466\n",
      "\n",
      "Accuracy:  87.87510137875101\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def load_data(filename):\n",
    "    evidence = []\n",
    "    labels = []\n",
    "\n",
    "    month_index = {\n",
    "        \"Jan\": 0, \"Feb\": 1, \"Mar\": 2, \"Apr\": 3, \"May\": 4, \"June\": 5,\n",
    "        \"Jul\": 6, \"Aug\": 7, \"Sep\": 8, \"Oct\": 9, \"Nov\": 10, \"Dec\": 11\n",
    "    }\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            evidence.append([\n",
    "                int(row[\"Administrative\"]),\n",
    "                float(row[\"Administrative_Duration\"]),\n",
    "                int(row[\"Informational\"]),\n",
    "                float(row[\"Informational_Duration\"]),\n",
    "                int(row[\"ProductRelated\"]),\n",
    "                float(row[\"ProductRelated_Duration\"]),\n",
    "                float(row[\"BounceRates\"]),\n",
    "                float(row[\"ExitRates\"]),\n",
    "                float(row[\"PageValues\"]),\n",
    "                float(row[\"SpecialDay\"]),\n",
    "                month_index[row[\"Month\"]],\n",
    "                int(row[\"OperatingSystems\"]),\n",
    "                int(row[\"Browser\"]),\n",
    "                int(row[\"Region\"]),\n",
    "                int(row[\"TrafficType\"]),\n",
    "                1 if row[\"VisitorType\"] == \"Returning_Visitor\" else 0,\n",
    "                1 if row[\"Weekend\"] == \"TRUE\" else 0,\n",
    "            ])\n",
    "            labels.append(1 if row[\"Revenue\"] == \"TRUE\" else 0)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    t_positive = float(0)\n",
    "    t_negative = float(0)\n",
    "    sensitivity = float(0)\n",
    "    specificity = float(0)\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == 0:\n",
    "            t_negative += 1\n",
    "            if label == prediction:\n",
    "                specificity += 1\n",
    "\n",
    "        if label == 1:\n",
    "            t_positive += 1\n",
    "            if label == prediction:\n",
    "                sensitivity += 1\n",
    "\n",
    "    sensitivity /= t_positive\n",
    "    specificity /= t_negative\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Replace 'Data/activity_data.csv' with the path to your CSV file\n",
    "filename = 'activity_data.csv'\n",
    "\n",
    "evidence, labels = load_data(filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVC with RBF kernel\n",
    "model_rbf = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "\n",
    "# Train the model\n",
    "model_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions_rbf = model_rbf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "sensitivity_rbf, specificity_rbf = evaluate(y_test, predictions_rbf)\n",
    "print(f\"SVM with RBF Kernel\")\n",
    "print(f\"Correct: {(y_test == predictions_rbf).sum()}\")\n",
    "print(f\"Incorrect: {(y_test != predictions_rbf).sum()}\")\n",
    "print(f\"True Positive Rate: {100 * sensitivity_rbf:.2f}%\")\n",
    "print(f\"True Negative Rate: {100 * specificity_rbf:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(y_test, predictions_rbf))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions_rbf) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f7f9a",
   "metadata": {},
   "source": [
    "# SVM with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4795d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Polynomial Kernel\n",
      "Correct: 2151\n",
      "Incorrect: 315\n",
      "True Positive Rate: 34.06%\n",
      "True Negative Rate: 97.86%\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      2055\n",
      "           1       0.76      0.34      0.47       411\n",
      "\n",
      "    accuracy                           0.87      2466\n",
      "   macro avg       0.82      0.66      0.70      2466\n",
      "weighted avg       0.86      0.87      0.85      2466\n",
      "\n",
      "Accuracy:  87.22627737226277\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with StandardScaler and SVC with Polynomial kernel\n",
    "model_poly = make_pipeline(StandardScaler(), SVC(kernel='poly', degree=3))\n",
    "\n",
    "# Train the model\n",
    "model_poly.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions_poly = model_poly.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "sensitivity_poly, specificity_poly = evaluate(y_test, predictions_poly)\n",
    "print(f\"SVM with Polynomial Kernel\")\n",
    "print(f\"Correct: {(y_test == predictions_poly).sum()}\")\n",
    "print(f\"Incorrect: {(y_test != predictions_poly).sum()}\")\n",
    "print(f\"True Positive Rate: {100 * sensitivity_poly:.2f}%\")\n",
    "print(f\"True Negative Rate: {100 * specificity_poly:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(y_test, predictions_poly))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions_poly) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa656e39",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104d63aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Correct: 2173\n",
      "Incorrect: 293\n",
      "True Positive Rate: 45.01%\n",
      "True Negative Rate: 96.74%\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      2055\n",
      "           1       0.73      0.45      0.56       411\n",
      "\n",
      "    accuracy                           0.88      2466\n",
      "   macro avg       0.82      0.71      0.74      2466\n",
      "weighted avg       0.87      0.88      0.87      2466\n",
      "\n",
      "Accuracy:  88.1184103811841\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def load_data(filename):\n",
    "    evidence = []\n",
    "    labels = []\n",
    "\n",
    "    month_index = {\n",
    "        \"Jan\": 0, \"Feb\": 1, \"Mar\": 2, \"Apr\": 3, \"May\": 4, \"June\": 5,\n",
    "        \"Jul\": 6, \"Aug\": 7, \"Sep\": 8, \"Oct\": 9, \"Nov\": 10, \"Dec\": 11\n",
    "    }\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            evidence.append([\n",
    "                int(row[\"Administrative\"]),\n",
    "                float(row[\"Administrative_Duration\"]),\n",
    "                int(row[\"Informational\"]),\n",
    "                float(row[\"Informational_Duration\"]),\n",
    "                int(row[\"ProductRelated\"]),\n",
    "                float(row[\"ProductRelated_Duration\"]),\n",
    "                float(row[\"BounceRates\"]),\n",
    "                float(row[\"ExitRates\"]),\n",
    "                float(row[\"PageValues\"]),\n",
    "                float(row[\"SpecialDay\"]),\n",
    "                month_index[row[\"Month\"]],\n",
    "                int(row[\"OperatingSystems\"]),\n",
    "                int(row[\"Browser\"]),\n",
    "                int(row[\"Region\"]),\n",
    "                int(row[\"TrafficType\"]),\n",
    "                1 if row[\"VisitorType\"] == \"Returning_Visitor\" else 0,\n",
    "                1 if row[\"Weekend\"] == \"TRUE\" else 0,\n",
    "            ])\n",
    "            labels.append(1 if row[\"Revenue\"] == \"TRUE\" else 0)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    t_positive = float(0)\n",
    "    t_negative = float(0)\n",
    "    sensitivity = float(0)\n",
    "    specificity = float(0)\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == 0:\n",
    "            t_negative += 1\n",
    "            if label == prediction:\n",
    "                specificity += 1\n",
    "\n",
    "        if label == 1:\n",
    "            t_positive += 1\n",
    "            if label == prediction:\n",
    "                sensitivity += 1\n",
    "\n",
    "    sensitivity /= t_positive\n",
    "    specificity /= t_negative\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Replace 'Data/activity_data.csv' with the path to your CSV file\n",
    "filename = 'activity_data.csv'\n",
    "\n",
    "evidence, labels = load_data(filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Define the parameter grid for RBF and Polynomial kernels\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__kernel': ['rbf'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__gamma': [1, 0.1, 0.01, 0.001]\n",
    "    },\n",
    "    {\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__degree': [2, 3, 4],\n",
    "        'svc__gamma': ['scale', 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVC\n",
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "sensitivity, specificity = evaluate(y_test, predictions)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Correct: {(y_test == predictions).sum()}\")\n",
    "print(f\"Incorrect: {(y_test != predictions).sum()}\")\n",
    "print(f\"True Positive Rate: {100 * sensitivity:.2f}%\")\n",
    "print(f\"True Negative Rate: {100 * specificity:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
