{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2073a8e",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def load_data(filename):\n",
    "    evidence = []\n",
    "    labels = []\n",
    "\n",
    "    month_index = {\n",
    "        \"Jan\": 0, \"Feb\": 1, \"Mar\": 2, \"Apr\": 3, \"May\": 4, \"June\": 5,\n",
    "        \"Jul\": 6, \"Aug\": 7, \"Sep\": 8, \"Oct\": 9, \"Nov\": 10, \"Dec\": 11\n",
    "    }\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            evidence.append([\n",
    "                int(row[\"Administrative\"]),\n",
    "                float(row[\"Administrative_Duration\"]),\n",
    "                int(row[\"Informational\"]),\n",
    "                float(row[\"Informational_Duration\"]),\n",
    "                int(row[\"ProductRelated\"]),\n",
    "                float(row[\"ProductRelated_Duration\"]),\n",
    "                float(row[\"BounceRates\"]),\n",
    "                float(row[\"ExitRates\"]),\n",
    "                float(row[\"PageValues\"]),\n",
    "                float(row[\"SpecialDay\"]),\n",
    "                month_index[row[\"Month\"]],\n",
    "                int(row[\"OperatingSystems\"]),\n",
    "                int(row[\"Browser\"]),\n",
    "                int(row[\"Region\"]),\n",
    "                int(row[\"TrafficType\"]),\n",
    "                1 if row[\"VisitorType\"] == \"Returning_Visitor\" else 0,\n",
    "                1 if row[\"Weekend\"] == \"TRUE\" else 0,\n",
    "            ])\n",
    "            labels.append(1 if row[\"Revenue\"] == \"TRUE\" else 0)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    t_positive = float(0)\n",
    "    t_negative = float(0)\n",
    "    sensitivity = float(0)\n",
    "    specificity = float(0)\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == 0:\n",
    "            t_negative += 1\n",
    "            if label == prediction:\n",
    "                specificity += 1\n",
    "\n",
    "        if label == 1:\n",
    "            t_positive += 1\n",
    "            if label == prediction:\n",
    "                sensitivity += 1\n",
    "\n",
    "    sensitivity /= t_positive\n",
    "    specificity /= t_negative\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Replace 'Data/activity_data.csv' with the path to your CSV file\n",
    "filename = 'activity_data.csv'\n",
    "\n",
    "evidence, labels = load_data(filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Define the parameter grid for RBF and Polynomial kernels\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__kernel': ['rbf'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__gamma': [1, 0.1, 0.01, 0.001]\n",
    "    },\n",
    "    {\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__degree': [2, 3, 4],\n",
    "        'svc__gamma': ['scale', 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVC\n",
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "sensitivity, specificity = evaluate(y_test, predictions)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Correct: {(y_test == predictions).sum()}\")\n",
    "print(f\"Incorrect: {(y_test != predictions).sum()}\")\n",
    "print(f\"True Positive Rate: {100 * sensitivity:.2f}%\")\n",
    "print(f\"True Negative Rate: {100 * specificity:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917078f3",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Randomised Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36599055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def load_data(filename):\n",
    "    evidence = []\n",
    "    labels = []\n",
    "\n",
    "    month_index = {\n",
    "        \"Jan\": 0, \"Feb\": 1, \"Mar\": 2, \"Apr\": 3, \"May\": 4, \"June\": 5,\n",
    "        \"Jul\": 6, \"Aug\": 7, \"Sep\": 8, \"Oct\": 9, \"Nov\": 10, \"Dec\": 11\n",
    "    }\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            evidence.append([\n",
    "                int(row[\"Administrative\"]),\n",
    "                float(row[\"Administrative_Duration\"]),\n",
    "                int(row[\"Informational\"]),\n",
    "                float(row[\"Informational_Duration\"]),\n",
    "                int(row[\"ProductRelated\"]),\n",
    "                float(row[\"ProductRelated_Duration\"]),\n",
    "                float(row[\"BounceRates\"]),\n",
    "                float(row[\"ExitRates\"]),\n",
    "                float(row[\"PageValues\"]),\n",
    "                float(row[\"SpecialDay\"]),\n",
    "                month_index[row[\"Month\"]],\n",
    "                int(row[\"OperatingSystems\"]),\n",
    "                int(row[\"Browser\"]),\n",
    "                int(row[\"Region\"]),\n",
    "                int(row[\"TrafficType\"]),\n",
    "                1 if row[\"VisitorType\"] == \"Returning_Visitor\" else 0,\n",
    "                1 if row[\"Weekend\"] == \"TRUE\" else 0,\n",
    "            ])\n",
    "            labels.append(1 if row[\"Revenue\"] == \"TRUE\" else 0)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    t_positive = float(0)\n",
    "    t_negative = float(0)\n",
    "    sensitivity = float(0)\n",
    "    specificity = float(0)\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == 0:\n",
    "            t_negative += 1\n",
    "            if label == prediction:\n",
    "                specificity += 1\n",
    "\n",
    "        if label == 1:\n",
    "            t_positive += 1\n",
    "            if label == prediction:\n",
    "                sensitivity += 1\n",
    "\n",
    "    sensitivity /= t_positive\n",
    "    specificity /= t_negative\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "\n",
    "# Replace 'Data/activity_data.csv' with the path to your CSV file\n",
    "filename = 'activity_data.csv'\n",
    "\n",
    "evidence, labels = load_data(filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Define the parameter distribution for RBF and Polynomial kernels\n",
    "param_dist = {\n",
    "    'svc__kernel': ['rbf', 'poly'],\n",
    "    'svc__C': uniform(0.1, 100),\n",
    "    'svc__gamma': uniform(0.001, 0.1),\n",
    "    'svc__degree': randint(2, 5)  # Only relevant for 'poly' kernel\n",
    "}\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVC\n",
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=50, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after randomized search\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "sensitivity, specificity = evaluate(y_test, predictions)\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Correct: {(y_test == predictions).sum()}\")\n",
    "print(f\"Incorrect: {(y_test != predictions).sum()}\")\n",
    "print(f\"True Positive Rate: {100 * sensitivity:.2f}%\")\n",
    "print(f\"True Negative Rate: {100 * specificity:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e1512",
   "metadata": {},
   "source": [
    "# Randomised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66cfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def load_data(filename):\n",
    "    evidence = []\n",
    "    labels = []\n",
    "\n",
    "    month_index = {\n",
    "        \"Jan\": 0, \"Feb\": 1, \"Mar\": 2, \"Apr\": 3, \"May\": 4, \"June\": 5,\n",
    "        \"Jul\": 6, \"Aug\": 7, \"Sep\": 8, \"Oct\": 9, \"Nov\": 10, \"Dec\": 11\n",
    "    }\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            evidence.append([\n",
    "                int(row[\"Administrative\"]),\n",
    "                float(row[\"Administrative_Duration\"]),\n",
    "                int(row[\"Informational\"]),\n",
    "                float(row[\"Informational_Duration\"]),\n",
    "                int(row[\"ProductRelated\"]),\n",
    "                float(row[\"ProductRelated_Duration\"]),\n",
    "                float(row[\"BounceRates\"]),\n",
    "                float(row[\"ExitRates\"]),\n",
    "                float(row[\"PageValues\"]),\n",
    "                float(row[\"SpecialDay\"]),\n",
    "                month_index[row[\"Month\"]],\n",
    "                int(row[\"OperatingSystems\"]),\n",
    "                int(row[\"Browser\"]),\n",
    "                int(row[\"Region\"]),\n",
    "                int(row[\"TrafficType\"]),\n",
    "                1 if row[\"VisitorType\"] == \"Returning_Visitor\" else 0,\n",
    "                1 if row[\"Weekend\"] == \"TRUE\" else 0,\n",
    "            ])\n",
    "            labels.append(1 if row[\"Revenue\"] == \"TRUE\" else 0)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    t_positive = float(0)\n",
    "    t_negative = float(0)\n",
    "    sensitivity = float(0)\n",
    "    specificity = float(0)\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == 0:\n",
    "            t_negative += 1\n",
    "            if label == prediction:\n",
    "                specificity += 1\n",
    "\n",
    "        if label == 1:\n",
    "            t_positive += 1\n",
    "            if label == prediction:\n",
    "                sensitivity += 1\n",
    "\n",
    "    sensitivity /= t_positive\n",
    "    specificity /= t_negative\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "filename = 'activity_data.csv'\n",
    "\n",
    "evidence, labels = load_data(filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "param_distributions = [\n",
    "    {\n",
    "        'svc__kernel': ['rbf'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__gamma': [1, 0.1, 0.01, 0.001]\n",
    "    },\n",
    "    {\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__degree': [2, 3, 4],\n",
    "        'svc__gamma': ['scale', 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), PCA(n_components=10), SVC())\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, predictions)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
